\documentclass[10pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for for rotated page geometry
\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}

\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{9in}
\setlength{\textwidth}{7in}
\setlength{\oddsidemargin}{-.25in}

\title{Permutation Generation with Heap's Algorithm and the Steinhaus-Johnson-Trotter Algorithm}
\author{Ryan Bernstein \\ Ruben Niculcea \\ Levi Schoen}
\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Heap's Algorithm}

\subsection{Proof of Termination}

\subsection{Proof of Correctness}

\subsection{Time Complexity}

The significant portion of our implementation of Heap's Algorithm is as follows:
\begin{verbatim}
  3 def heaps(set, time=False):
  4   def innerHeaps(n, set):
  5     if n == 1:
  6       print set
  7     else:
  8       for i in range(n):
  9         innerHeaps(n-1, set)
 10         if n % 2 == 1: #odd number
 11           j = 0
 12         else:
 13           j = i
 14         set[j], set[n-1] = set[n-1], set[j] #swap
\end{verbatim}

We'll analyze the running time of this algorithm in terms of swaps, comparisons, assignments, and processes. From the code above, we can count how many times each of these operations is performed, \emph{not} including work done within the recursive calls.
\begin{description}
\item Swaps ($O(1)$)

	The swap operation appears only once in our implementation, on line 14. This line is never executed when $n=1$; if $n > 1$, the loop containing it executes $n$ times.

\item Comparisons ($O(1)$)

	A comparison appears on line 5 regardless of the current value of $n$. Another comparison appears within the loop on line 10, which executes $n$ times for all $n > 1$. The second comparison also includes a division for modular arithmetic; we will also consider this an $O(n)$ operation.

\item Assignments ($O(1)$)

	Not counting the assignments that appear within the swaps, a single assignment occurs on either line 11 or line 13. This is dependent on the result of the comparison on line 10.

\item Processes/\texttt{print}s ($O(n)$)

	We only process a permutation in the base case of our recursion, when $n = 1$. Thus we execute a process once when $n = 1$ and 0 times in any other case.
\end{description}

\subsubsection{Factoring In Recursion}

Our total number of operations (not counting recursion) can be represented by the following table:

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
	\hline
	Input Size & 1 & 2 & 3 & 4 & 5 & $n > 1$\\
	\hline
	Swaps & 0 & 2 & 3 & 4 & 5 & $n$\\
	\hline
	Comparisons & 1 & 3 & 4 & 5 & 6 & $n + 1$ \\
	\hline
	Assignments & 0 & 2 & 3 & 4 & 5 & $n$ \\
	\hline
	Processes & 1 & 0 & 0 & 0 & 0 & 0 \\
	\hline
	Recursive calls & 0 & 2 & 3 & 4 & 5 & $n$ \\
	\hline
\end{tabular}
\end{center}

Looking only at the recursive calls, it becomes clear that the number of recursive calls made for an input of size $n$ is 0 when $n = 1$ and $n$ for any $n > 1$ (we can confirm this by looking at the loop in our code). It follows that if we wish to include operations executed within recursive calls, the total number of times that each operation will execute on an input of size $n$ will be the number of times that this operation executes in the work function plus $n$ times the number of times that operation is performed for an input of size $n - 1$.

This means that with recursion factored in, the total number of swaps, assignments, and recursive calls can be expressed as follows:
\begin{align*}
	T(n) &= n \cdot T(n - 1) + n \\
	\frac{T(n)}{n!} &= \frac{T(n - 1)}{(n - 1)!} + \frac{1}{(n - 1)!} &\text{Divide by $n!$} \\
	&= \sum_{i = 1}^{n} \frac{1}{(i - 1)!} &\text{Since $T(1) = 0$} \\
	&= \sum_{i = 1}^{n - 1} \frac{1}{i!} \\
	T(n) &= n! \cdot \sum_{i = 1}^{n - 1} \frac{1}{i!} &\text{Multiply by $n!$}
\end{align*}

The number of comparisons is similar:
\begin{align*}
	T(n) &= n \cdot T(n - 1) + n + 1 \\
	\frac{T(n)}{n!} &= \frac{T(n - 1)}{(n - 1)!} + \frac{1}{(n - 1)!} + \frac{1}{n!} &\text{Divide by $n!$} \\
	&= 1 + \frac{1}{(n - 1)!} + \frac{1}{n!} &\text{Since $T(1) = 0! = 1$} \\
	&= 1 + \sum_{i = 1}^{n - 1} \frac{1}{i!} + \sum_{i = 1}^{n} \frac{1}{i!} \\
	&= 1 + 2 \sum_{i = 1}^{n - 1} \frac{1}{i!} + \frac{1}{n!} \\
	T(n) &= n! + 2n! \sum_{i = 1}^{n - 1} \frac{1}{i!} + 1 &\text{Multiply by $n!$}
\end{align*}

Combining this with the time complexity of each operation, the overall time complexity is therefore as follows:
\begin{align*}
	&2 \cdot \left( n! \cdot \sum_{i = 1}^{n - 1} \frac{1}{i!} \right) + \left( n! + 2n! \cdot \sum_{i = 1}^{n - 1} \frac{1}{i!} + 1 \right) + n \\
	&= n! \cdot \left(1 + 4 \cdot \sum_{1}^{n - 1} \frac{1}{i!} \right) + 1 + n
\end{align*}

\subsection{Space Complexity}

Looking at the code above, we can see that we use the same set object throughout the series of recursive calls. Beyond that, since our recursion decrements $n$ each time and stops at 1, we will have at most $n$ (constant-size) stack-frames at any given time.

The space complexity of Heap's algorithm is therefore $O(n)$.

\section{The Steinhaus-Johnson-Trotter Algorithm}

\newtheorem{axiom}{Axiom}[section]
\newtheorem{lemma}{Lemma}[section]

\subsection{Proof of Termination}

\subsection{Proof of Correctness}

\subsection{Time Complexity}

Our proof of correctness shows that this algorithm correctly generates all $n!$ permutations of an $n$-element set; this means that our loop will run $n!$ times. However, unlike Heap's algorithm, this loop will not perform the same number of steps every time. Each loop iteration will perform:
\begin{itemize}
	\item A search for the largest mobile element, which is broken into $n$ mobility checks and $c$ comparisons against the current largest mobile element (where $c$ is the sum of the numbers of mobile elements for each iteration)
	\item A single $O(n)$ \texttt{process}
	\item Some number of $O(1)$ direction reversals
	\item One $O(1)$ swap
\end{itemize}
How can we determine the number of direction reversals? The key lies in our definition of mobility and the following fact: for each case in which item $a_{i}$ is the largest mobile element (LME), we will perform a reversal for each item $a_{j} > a_{i}$ in our set. We can therefore define the total number of reversals across \emph{all} iterations as follows:
\[
	R_{\text{total}} = \sum_{i = 1}^{n} \left( (\text{number of times $a_{i}$ is the LME}) \cdot (n - i) \right)
\]

\subsubsection{Solving for Largest Mobile Element Counts}

We say that an element is mobile if and only if it points to a smaller element. Based on this definition, I propose the following axioms:
\begin{axiom}
	Since $a_{n}$ is the largest element in the set, this means that any time it is mobile, it will be the largest mobile element.
\end{axiom}
\begin{axiom}
	Furthermore, $a_{n}$ will only be \emph{immobile} if it points at an edge. At this point, if another mobile element exists, $a_{n}$ will reverse direction; otherwise, no mobile elements exist and our loop terminates. Since we are sweeping $a_{n}$ back and forth across all $(n - 1)$-element permutations, it will point to an edge and lose mobility once for each of these.
\end{axiom}
\begin{axiom}
	An element $a_{i}$ can be mobile in an $n$-element permutation $\pi$ if and only if it would be mobile in the $i$-element permutation $\pi - a_{j}$ for all $j > i$.
\end{axiom}
Extending axiom 2.3, we can see the following: since we're assuming that each possible permutation of an $(n - 1)$-element set appears $n$ times in permutations of an $n$-element set, any $(n - 1)$-element permutation $\pi_{n - 1}$ in which $a_{n - 1}$ is the LME will appear $n$ times in permutations of $n$ elements. Of these, $a_{n}$ will be the LME in any case where it is mobile by axiom 2.1. Since $a_{n}$ will be mobile for all but one of the $n$ repetitions of $\pi_{n - 1}$. In this permutation $\pi$, $a_{n - 1}$ is the LME of $\pi - a_{n}$ and $a_{n}$ is immobile. Therefore, $a_{n - 1}$ is the LME in $\pi$.

We can therefore conclude that in permutations of $n$ elements, $a_{n - 1}$ is the LME exactly once for every $(n - 1)$-element permutation for which $a_{n - 1}$ is the LME. By axiom 2.1, this is any $(n - 1)$-element permutation in which $a_{n - 1}$ is mobile.

Axiom 2.2 tells us that $a_{n}$ loses mobility exactly once for each $(n - 1)$-element permutation, of which there are $(n - 1)!$. Therefore, the number of times $a_{n}$ is the largest mobile element in a permutation of $m$ elements for all $m \geq n$ is equal to exactly $n! - (n - 1)!$.

Substituting this back into our equation for $R_{\text{total}}$, we get the following result:
\[
	R_{\text{total}} = \sum_{i = 1}^{n} \left( \left( i! - (i - 1)! \right) \cdot \left( n - i \right) \right)
\]

\subsubsection{Mobility Counts}

We can solve for mobility counts in a similar fashion. Every $(n - 1)$-element permutation appears $n$ times in the set of $n$-elements. Element $a_{n}$ will be swept across each position in $\pi_{n - 1}$. The combination of these two facts tells us that if an element $a_{i}$ is mobile in $\pi_{n - 1}$, it will be mobile in every $n$-element permutation that extends $\pi_{n - 1}$ except for the one case in which $a_{n}$ is between $a_{i}$ and the (smaller) element that $a_{i}$ points to.

We know that $a_{n}$ is mobile in $(n! - (n - 1)!)$ of the $n$-element permutations in which it first appears. By this reasoning, it will now be mobile in $n \cdot (n! - (n - 1)!)$ permutations of $n + 1$ elements, $(n + 1) \cdot n \cdot (n! - (n - 1)!)$ permutations of $n + 2$ elements, and so on.

We can therefore solve for the total number of mobile elements across all iterations (which is also the total number of comparisons made to find the largest mobile element in each iteration) as follows:
\[
	C_{\text{total}} = \sum_{i = 1}^{n} \left( \left( i! - (i - 1)! \right) \cdot \frac{(n - 1)!}{(i - 1)!} \right)
\]

The overall time complexity of the Steinhaus-Johnson-Trotter algorithm is therefore:
\[
	n! \cdot (2n + 1)+ \sum_{i = 1}^{n} \left( \left( i! - (i - 1)! \right) \cdot \frac{(n - 1)!}{(i - 1)!} \right) + \sum_{i = 1}^{n} \left( \left(i! - (i - 1)! \right) \cdot \left( n - i \right) \right) 
\]

\subsection{Space Complexity}

\end{document}  